{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier,RidgeClassifierCV,LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,TreebankWordTokenizer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from emoji.unicode_codes import UNICODE_EMOJI\n",
    "import emoji\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('28_task_result.csv', sep = ';', names = ['comment', 'level', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>level</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Спасибо !</td>\n",
       "      <td>simpleTree</td>\n",
       "      <td>общеразговорные</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ставропольский край . г Ессентуки . ул Октябрь...</td>\n",
       "      <td>simpleTree</td>\n",
       "      <td>вопросы о сервисе</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Здравствуйте **** . Можно ли заказать следующи...</td>\n",
       "      <td>simpleTree</td>\n",
       "      <td>вопросы о товаре</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Спасибо )</td>\n",
       "      <td>simpleTree</td>\n",
       "      <td>общеразговорные</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Можете сказать фирму блузы ?</td>\n",
       "      <td>simpleTree</td>\n",
       "      <td>вопросы о товаре</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment       level  \\\n",
       "0                                         Спасибо !   simpleTree   \n",
       "1  Ставропольский край . г Ессентуки . ул Октябрь...  simpleTree   \n",
       "2  Здравствуйте **** . Можно ли заказать следующи...  simpleTree   \n",
       "3                                         Спасибо )   simpleTree   \n",
       "4                      Можете сказать фирму блузы ?   simpleTree   \n",
       "\n",
       "               label  \n",
       "0    общеразговорные  \n",
       "1  вопросы о сервисе  \n",
       "2   вопросы о товаре  \n",
       "3    общеразговорные  \n",
       "4   вопросы о товаре  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "другие               0.49600\n",
       "вопросы о сервисе    0.19150\n",
       "вопросы о товаре     0.14450\n",
       "общеразговорные      0.14175\n",
       "более 1 категории    0.02625\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.label.value_counts()/comments.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['label_num'] = comments.label.map({'другие':0, 'вопросы о сервисе':1, 'вопросы о товаре':2, 'общеразговорные':3, 'более 1 категории':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vect = CountVectorizer(ngram_range = (1,1), analyzer = 'word',\n",
    "                       stop_words = 'english',\n",
    "                       max_features = 500,\n",
    "                       min_df = 2, max_df = 0.95).fit(comments.comment)\n",
    "pw = list(vect.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pw.txt\", \"w\") as text_file:\n",
    "    for w in pw:\n",
    "        print(w, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_spelling(text):\n",
    "    if not c.check(text):\n",
    "        suggestions = list(set(c.suggest(text)))#.intersection(set(pw)))\n",
    "        if len(suggestions)>0:\n",
    "            res = suggestions[0]\n",
    "        elif len(c.suggest(text))>0:\n",
    "            res = c.suggest(text)[0]\n",
    "        else:\n",
    "            res = text\n",
    "    else:\n",
    "        res = text\n",
    "    return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def clean_comment(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    text = re.sub(r'\\W',' ', text)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    processed = []\n",
    "    #processed = [wnl.lemmatize(check_spelling(word),get_wordnet_pos(tag)) if get_wordnet_pos(tag)!='' else wnl.lemmatize(check_spelling(word)) for (word,tag) in tags]\n",
    "    for (word, tag) in tags:\n",
    "        wn_tag = get_wordnet_pos(tag)\n",
    "        if wn_tag!='':\n",
    "            processed.append(wnl.lemmatize(check_spelling(word),wn_tag))\n",
    "        else:\n",
    "            processed.append(wnl.lemmatize(check_spelling(word)))\n",
    "    res = ' '.join(processed)\n",
    "    return res.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.11315321922302246 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clean_comment('Заплоти пес')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['cleaned'] = comments.comment.apply(clean_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              спасибо\n",
       "1    ставропольский край гр ессентуки ул октябрьска...\n",
       "2    здравствуйте можно ли заказать следующие модел...\n",
       "3                                              спасибо\n",
       "4                           можете сказать фирму блузы\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'здравствуйте у вас есть номер отслеживания моего заказа что то не пришел еще думаю может на почте спросить по номеру'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.cleaned.iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comments.to_csv('comments_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_score: 0.6333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "vect = CountVectorizer()\n",
    "model = LogisticRegressionCV()\n",
    "scaler = MaxAbsScaler()\n",
    "stop_words = stopwords.words('russian')\n",
    "lin_model = Pipeline([#('vectorizer', vect),\n",
    "                      ('features', FeatureUnion([\n",
    "                        ('words', CountVectorizer(ngram_range = (1,3), max_features = 500,analyzer = 'word', stop_words = stop_words)),\n",
    "                        ('chars', CountVectorizer(ngram_range = (1,5), max_features = 500,analyzer = 'char', stop_words = stop_words)),\n",
    "                      ])),\n",
    "                        #('scaler', scaler),\n",
    "                      ('classifier', model)])\n",
    "lin_model.set_params(classifier__class_weight = 'balanced')#,classifier__alphas = np.linspace(start = 0.01, stop = 100, num = 50))\n",
    "feats = comments.cleaned\n",
    "labels = comments.label_num\n",
    "lin_model = lin_model.fit(feats, labels)\n",
    "print('cross_val_score: %1.4f'% (np.mean(cross_val_score(lin_model, feats,labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pipeline(input_text, model = lin_model):\n",
    "    cleaned_text = clean_comment(input_text)\n",
    "    class_names = ['другие',\n",
    "        'вопросы о сервисе',\n",
    "        'вопросы о товаре',\n",
    "        'общеразговорные',\n",
    "        'более 1 категории']\n",
    "    prediction = model.predict([cleaned_text])\n",
    "    #print(class_names[prediction[0]])\n",
    "    return class_names[prediction[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'вопросы о товаре'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pipeline('Здравствуйте. У вас есть синие комбинезоны? Адрес: г. Новочеркасск, ул. Щорса 83, кв. 57')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
